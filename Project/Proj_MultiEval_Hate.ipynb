{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj_MultiEval_Hate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8k9fOLc+wwp7LxldvfQYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheeltahir55/CE888/blob/main/Project/Proj_MultiEval_Hate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkyENKK0qsMJ"
      },
      "source": [
        "### HATE ####\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk import pos_tag\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from collections import defaultdict\r\n",
        "from nltk.corpus import wordnet as wn\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import model_selection, naive_bayes, svm\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "import io\r\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1yoo0pPHfs",
        "outputId": "958885ef-2ace-4374-dcd3-e7eb5871c972"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z45Qnw2Xu7eL"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAG5RCVC9pew"
      },
      "source": [
        "#import base64\r\n",
        "#import requests\r\n",
        "\r\n",
        "#master = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt\"\r\n",
        "#req = requests.get(master)\r\n",
        "#req = req.text\r\n",
        "#for line in req:\r\n",
        "#   print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RisVedtg0gEo"
      },
      "source": [
        "# from google.colab import files\r\n",
        "# uploaded= files.upload()\r\n",
        "# file= \"Train_Text.txt\"\r\n",
        "# uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "\r\n",
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_text.txt', allow_redirects= True)\r\n",
        "open('train_text.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/train_text.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data = file1.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1omFKZNL-R2r"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_labels.txt', allow_redirects= True)\r\n",
        "open('train_labels.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/train_labels.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data1 = file1.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnoyei5LtIuO"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt', allow_redirects= True)\r\n",
        "open('test_text.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/test_text.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data2 = file1.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsOfLjwQtMaE"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_labels.txt', allow_redirects= True)\r\n",
        "open('test_labels.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/test_labels.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data3 = file1.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78VNicp0JDC"
      },
      "source": [
        "# data = uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data1 = uploaded1[file1].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data2 = uploaded2[file2].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data3 = uploaded3[file3].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "\r\n",
        "data= [data[i].strip() for i in range(len(data))]\r\n",
        "data1= [data1[i].strip() for i in range(len(data1))]\r\n",
        "data2= [data2[i].strip() for i in range(len(data2))]\r\n",
        "data3= [data3[i].strip() for i in range(len(data3))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWgZGMiHV2v"
      },
      "source": [
        "### df dataframe is training data\r\n",
        "\r\n",
        "df= pd.DataFrame()\r\n",
        "df['Text']=range(0, len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNlc9edVFmS3",
        "outputId": "dbaf369c-acfa-4416-f59a-1e67483d778b"
      },
      "source": [
        "for i in range(len(data)):\r\n",
        "  df.iloc[i, df.columns.get_loc('Text')]= data[i]\r\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text\n",
            "0  @user nice new signage. Are you not concerned ...\n",
            "1  A woman who you fucked multiple times saying y...\n",
            "2  @user @user real talk do you have eyes or were...\n",
            "3  your girlfriend lookin at me like a groupie in...\n",
            "4                        Hysterical woman like @user\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQzdmeOMhjJ"
      },
      "source": [
        "df['Label']=range(0, len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_JzW3rwM5nf",
        "outputId": "7ccb9d5c-f80f-43aa-97ae-498170847e6a"
      },
      "source": [
        "for i in range(len(data1)):\r\n",
        "  df.iloc[i, df.columns.get_loc('Label')]= data1[i]\r\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user nice new signage. Are you not concerned ...     0\n",
            "1  A woman who you fucked multiple times saying y...     1\n",
            "2  @user @user real talk do you have eyes or were...     1\n",
            "3  your girlfriend lookin at me like a groupie in...     1\n",
            "4                        Hysterical woman like @user     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIFphT7NNElc"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\r\n",
        "df['Text'].dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ko_Sa_MNYGR"
      },
      "source": [
        "# Step - b : Change all the text to lower case.\r\n",
        "df['Text'] = [entry.lower() for entry in df['Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "fcKe9U0dN0ap",
        "outputId": "404e859b-b03d-4ea7-9d09-9e0e66773214"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user nice new signage. are you not concerned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a woman who you fucked multiple times saying y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user real talk do you have eyes or were...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hysterical woman like @user</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label\n",
              "0  @user nice new signage. are you not concerned ...     0\n",
              "1  a woman who you fucked multiple times saying y...     1\n",
              "2  @user @user real talk do you have eyes or were...     1\n",
              "3  your girlfriend lookin at me like a groupie in...     1\n",
              "4                        hysterical woman like @user     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sULiTbrlN6-X"
      },
      "source": [
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\r\n",
        "df['Text']= [word_tokenize(entry) for entry in df['Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "3mTnI5pqPPKB",
        "outputId": "89ad05ba-d37e-4af6-fae6-f65cad74c668"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label\n",
              "0  [@, user, nice, new, signage, ., are, you, not...     0\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...     1\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...     1\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...     1\n",
              "4                 [hysterical, woman, like, @, user]     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNO2bnB7PjUs"
      },
      "source": [
        "def preprocess(text):\r\n",
        "    new_text = []\r\n",
        "    for t in text.split(\" \"):\r\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\n",
        "        t = 'http' if t.startswith('http') else t\r\n",
        "        new_text.append(t)\r\n",
        "    return \" \".join(new_text)\r\n",
        "#df['Text']= [preprocess(entry) for entry in df['Text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEUE1JPqQfWA"
      },
      "source": [
        "for entry in df['Text']:\r\n",
        "  print(entry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQMsdLPrSNWb"
      },
      "source": [
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\r\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\r\n",
        "tag_map['J'] = wn.ADJ\r\n",
        "tag_map['V'] = wn.VERB\r\n",
        "tag_map['R'] = wn.ADV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNVBzx_tTKjl"
      },
      "source": [
        "for index,entry in enumerate(df['Text']):\r\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\r\n",
        "    Final_words = []\r\n",
        "    # Initializing WordNetLemmatizer()\r\n",
        "    word_Lemmatized = WordNetLemmatizer()\r\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\r\n",
        "    for word, tag in pos_tag(entry):\r\n",
        "        # Below condition is to check for Stop words and consider only alphabets\r\n",
        "        if word not in stopwords.words('english') and word.isalpha():\r\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\r\n",
        "            Final_words.append(word_Final)\r\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\r\n",
        "    df.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "NnCcgzWqTT0t",
        "outputId": "d2b9b8c0-e871-4cdd-f317-9f34af137652"
      },
      "source": [
        "df.head()\r\n",
        "#print(df['Text_Final'].dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'nice', 'new', 'signage', 'concern', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['woman', 'fuck', 'multiple', 'time', 'say', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'real', 'talk', 'eye', 'gouge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>['girlfriend', 'lookin', 'like', 'groupie', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "      <td>['hysterical', 'woman', 'like', 'user']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, nice, new, signage, ., are, you, not...  ...  ['user', 'nice', 'new', 'signage', 'concern', ...\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...  ...  ['woman', 'fuck', 'multiple', 'time', 'say', '...\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...  ...  ['user', 'user', 'real', 'talk', 'eye', 'gouge...\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...  ...  ['girlfriend', 'lookin', 'like', 'groupie', 'b...\n",
              "4                 [hysterical, woman, like, @, user]  ...            ['hysterical', 'woman', 'like', 'user']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG7Da5n9naBQ"
      },
      "source": [
        "#df['Text_Final']= df['Text_Final'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmEIUOFoJA8",
        "outputId": "20508623-8c7c-4842-ffc3-90ca7d28fb9b"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text          object\n",
            "Label         object\n",
            "Text_Final    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CWhanrYxvT8"
      },
      "source": [
        "### df1 dataframe is test data\r\n",
        "\r\n",
        "df1= pd.DataFrame()\r\n",
        "df1['Text']=range(0, len(data2))\r\n",
        "df1['Label']=range(0, len(data2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLKRaQVjxWH-",
        "outputId": "de8c1dde-b69c-41dd-c237-0781d3ac4bda"
      },
      "source": [
        "for i in range(len(data2)):\r\n",
        "  df1.iloc[i, df1.columns.get_loc('Text')]= data2[i]\r\n",
        "print(df1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text  Label\n",
            "0  @user , you are correct that Reid certainly is...      0\n",
            "1             Whoever just unfollowed me you a bitch      1\n",
            "2  @user @user Those People Invaded Us!!! They DO...      2\n",
            "3  stop JUDGING bitches by there cover, jus cuz s...      3\n",
            "4  how about i knock heads off and send them gift...      4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcjParajxiGG",
        "outputId": "c08fac75-3698-468d-ab86-90fc9a334a24"
      },
      "source": [
        "for i in range(len(data3)):\r\n",
        "  df1.iloc[i, df1.columns.get_loc('Label')]= data3[i]\r\n",
        "print(df1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user , you are correct that Reid certainly is...     0\n",
            "1             Whoever just unfollowed me you a bitch     1\n",
            "2  @user @user Those People Invaded Us!!! They DO...     1\n",
            "3  stop JUDGING bitches by there cover, jus cuz s...     1\n",
            "4  how about i knock heads off and send them gift...     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW_ISkXexALh"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\r\n",
        "\r\n",
        "#df1['Text']= df1['Text'].astype(str)\r\n",
        "\r\n",
        "df1['Text'].dropna(inplace=True)\r\n",
        "\r\n",
        "# Step - b : Change all the text to lower case.\r\n",
        "df1['Text'] = [entry.lower() for entry in df1['Text']]\r\n",
        "\r\n",
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\r\n",
        "df1['Text']= [word_tokenize(entry) for entry in df1['Text']]\r\n",
        "\r\n",
        "for index,entry in enumerate(df1['Text']):\r\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\r\n",
        "    Final_words = []\r\n",
        "    # Initializing WordNetLemmatizer()\r\n",
        "    word_Lemmatized = WordNetLemmatizer()\r\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\r\n",
        "    for word, tag in pos_tag(entry):\r\n",
        "        # Below condition is to check for Stop words and consider only alphabets\r\n",
        "        if word not in stopwords.words('english') and word.isalpha():\r\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\r\n",
        "            Final_words.append(word_Final)\r\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\r\n",
        "    df1.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "NLnug3v71yLm",
        "outputId": "c5731d5e-cf0c-4b58-a92e-55d2de399fe5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'nice', 'new', 'signage', 'concern', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['woman', 'fuck', 'multiple', 'time', 'say', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'real', 'talk', 'eye', 'gouge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>['girlfriend', 'lookin', 'like', 'groupie', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "      <td>['hysterical', 'woman', 'like', 'user']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, nice, new, signage, ., are, you, not...  ...  ['user', 'nice', 'new', 'signage', 'concern', ...\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...  ...  ['woman', 'fuck', 'multiple', 'time', 'say', '...\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...  ...  ['user', 'user', 'real', 'talk', 'eye', 'gouge...\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...  ...  ['girlfriend', 'lookin', 'like', 'groupie', 'b...\n",
              "4                 [hysterical, woman, like, @, user]  ...            ['hysterical', 'woman', 'like', 'user']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "XXmy5uss11ld",
        "outputId": "3372c615-f8f8-48b4-d131-9ca6805ad8d4"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, ,, you, are, correct, that, reid, ce...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'correct', 'reid', 'certainly', 'weas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[whoever, just, unfollowed, me, you, a, bitch]</td>\n",
              "      <td>1</td>\n",
              "      <td>['whoever', 'unfollowed', 'bitch']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, those, people, invaded, us,...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'people', 'invade', 'u', 'bel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[stop, judging, bitches, by, there, cover, ,, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['stop', 'judging', 'bitch', 'cover', 'jus', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[how, about, i, knock, heads, off, and, send, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['knock', 'head', 'send', 'gift', 'wrap', 'mom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, ,, you, are, correct, that, reid, ce...  ...  ['user', 'correct', 'reid', 'certainly', 'weas...\n",
              "1     [whoever, just, unfollowed, me, you, a, bitch]  ...                 ['whoever', 'unfollowed', 'bitch']\n",
              "2  [@, user, @, user, those, people, invaded, us,...  ...  ['user', 'user', 'people', 'invade', 'u', 'bel...\n",
              "3  [stop, judging, bitches, by, there, cover, ,, ...  ...  ['stop', 'judging', 'bitch', 'cover', 'jus', '...\n",
              "4  [how, about, i, knock, heads, off, and, send, ...  ...  ['knock', 'head', 'send', 'gift', 'wrap', 'mom...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0WvjkezXLX2",
        "outputId": "8854eeed-ea58-46f8-8b58-09b63a6c1aac"
      },
      "source": [
        "t_df= pd.concat([df, df1])\r\n",
        "\r\n",
        "#Tfidf_vect = TfidfVectorizer(max_features=5000)\r\n",
        "Tfidf_vect = TfidfVectorizer(max_features=6000)\r\n",
        "Tfidf_vect.fit(t_df['Text_Final'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=6000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwSwVLz45gpc",
        "outputId": "519b890a-8e9b-4d9f-fc8e-e2d7d96a5fde"
      },
      "source": [
        "t_df['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6935\n",
              "1    5035\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mK4jl99rPyU"
      },
      "source": [
        "Train_X= df['Text_Final']\r\n",
        "Train_Y= df['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvF8xPP_q_1S"
      },
      "source": [
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\r\n",
        "print(Train_X_Tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ncTyoHuzCPs",
        "outputId": "d2ceb321-2122-4dbc-ac2c-061573a90818"
      },
      "source": [
        "#df1['Text_Final']= df1['Text_Final'].astype(str)\r\n",
        "\r\n",
        "Tfidf_vect.fit(df1['Text_Final'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=6000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX1FP5ouzcWA"
      },
      "source": [
        "Test_X= df1['Text_Final']\r\n",
        "Test_Y= df1['Label']\r\n",
        "\r\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW863mYg0epV",
        "outputId": "e30a85d1-e93a-46ad-87a0-ea9bd7f9e0b5"
      },
      "source": [
        "print(Test_X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user', 'correct', 'reid', 'certainly', 'weasel', 'sadly', 'get', 'weasel', 'user', 'sen', 'mcconnell', 'user', 'corrupt', 'mueller', 'investigation', 'stop', 'maga', 'kag', 'potus', 'trump', 'news', 'votered', 'nodaca', 'usa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOtVjLqj5DYS",
        "outputId": "95dd4cc6-b31c-4cff-e8b8-4660e9089a95"
      },
      "source": [
        "print(Test_X_Tfidf[1,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5822)\t0.5234936774493395\n",
            "  (0, 5511)\t0.8316884955456674\n",
            "  (0, 577)\t0.18506381614878556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Hd-_B2zUvt",
        "outputId": "b7d998d9-cf62-4c57-d462-46d1767662a6"
      },
      "source": [
        "# fit the training dataset on the NB classifier\r\n",
        "Naive = naive_bayes.MultinomialNB()\r\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  55.218855218855225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S0jHE7p2xuf",
        "outputId": "25e3772f-897a-43ce-a287-7d6b89988a7d"
      },
      "source": [
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes F1 Score ->  50.257245383989236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCa7ijTJ0x-I",
        "outputId": "c76e5906-ed9e-49cf-ad2f-3294e78e1628"
      },
      "source": [
        "# Classifier - Algorithm - SVM\r\n",
        "# fit the training dataset on the classifier\r\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\r\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  57.13804713804714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLdB9AN48ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcf3a32-f4ac-47b0-b366-3b139384957e"
      },
      "source": [
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM F1 Score ->  40.77844621837827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MYH1rs0ejN",
        "outputId": "6e769b94-778b-4aff-db26-7bddca027e85"
      },
      "source": [
        "print(predictions_NB[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0' '1' '0' '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbwajj6f1QEv",
        "outputId": "63a2e52e-ecbb-4da4-e7de-2e9c71a462a3"
      },
      "source": [
        "print(predictions_SVM[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0' '0' '0' '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZEkGK2hScrI",
        "outputId": "19084ef1-0d93-4e95-f56e-08c2992c2324"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "parameters = {  \r\n",
        "'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)  \r\n",
        "}  \r\n",
        "grid_1= GridSearchCV(Naive, parameters)\r\n",
        "grid_1.fit(Train_X_Tfidf,Train_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 1e-05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ycfcSAiScur",
        "outputId": "027033f8-e014-4a7c-942e-06aad0d0fd7f"
      },
      "source": [
        "# print best parameter after tuning \r\n",
        "print(grid_1.best_params_) \r\n",
        "  \r\n",
        "# print how our model looks after hyper-parameter tuning \r\n",
        "print(grid_1.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1}\n",
            "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVlF8KFS_9s",
        "outputId": "e95f2f0a-c5b2-40be-e9ec-0a8fe0e5161f"
      },
      "source": [
        "# fit the training dataset on the NB classifier\r\n",
        "Naive = naive_bayes.MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\r\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\r\n",
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  55.218855218855225\n",
            "Naive Bayes F1 Score ->  50.257245383989236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJiEja_mJTdm",
        "outputId": "35b5a9c8-ef7c-484d-970e-7fee36fb7b2d"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \r\n",
        "  \r\n",
        "# defining parameter range \r\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \r\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "              'kernel': ['rbf']}  \r\n",
        "  \r\n",
        "grid = GridSearchCV(SVM, param_grid, refit = True, verbose = 3) \r\n",
        " \r\n",
        "# fitting the model for grid search \r\n",
        "grid.fit(Train_X_Tfidf,Train_Y) \r\n",
        "\r\n",
        "# print best parameter after tuning \r\n",
        "print(grid.best_params_) \r\n",
        "  \r\n",
        "# print how our model looks after hyper-parameter tuning \r\n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.617, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.614, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.612, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.611, total=   8.4s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.618, total=   8.5s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.582, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   8.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.770, total=   8.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.781, total=   8.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.785, total=   8.4s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.768, total=   8.2s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.771, total=   8.3s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.744, total=   7.5s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.750, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.746, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.584, total=   8.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.586, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   8.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.775, total=   9.5s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.771, total=   9.3s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.3s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.3s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.764, total=   6.9s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.762, total=   6.9s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.747, total=   6.8s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.750, total=   7.3s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.585, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.583, total=   8.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.586, total=   8.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   8.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.777, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.769, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.3s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.723, total=  11.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.731, total=  10.3s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.718, total=  10.1s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.721, total=  11.7s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.729, total=  10.2s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.753, total=   6.8s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.759, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.760, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.754, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.749, total=   6.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.759, total=   7.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.758, total=   7.3s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.3s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.585, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.583, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.586, total=   8.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.777, total=   9.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.769, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.722, total=  12.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.726, total=  10.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.718, total=  10.5s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.719, total=  10.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.724, total=  10.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.721, total=   9.2s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.726, total=   9.3s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.712, total=   9.1s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.706, total=   9.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.713, total=   9.2s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.752, total=   6.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.758, total=   6.7s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.757, total=   6.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.754, total=   6.7s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.748, total=   6.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.759, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.758, total=   7.5s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.752, total=   7.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 17.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
            "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIjmsiQ-P2Z5",
        "outputId": "b51947c3-bfd9-4c9f-972b-97c2edc25984"
      },
      "source": [
        "# Classifier - Algorithm - SVM\r\n",
        "# fit the training dataset on the classifier\r\n",
        "SVM = svm.SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\r\n",
        "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\r\n",
        "    probability=False, random_state=None, shrinking=True, tol=0.001,\r\n",
        "    verbose=False)\r\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\r\n",
        "\r\n",
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  56.93602693602694\n",
            "SVM F1 Score ->  37.60966387237823\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}