{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj_MultiEval_Hate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7kDQ5PiSX41gF4eHkmiuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheeltahir55/CE888/blob/main/Project/Proj_MultiEval_Hate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkyENKK0qsMJ"
      },
      "source": [
        "### HATE ####\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk import pos_tag\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from collections import defaultdict\r\n",
        "from nltk.corpus import wordnet as wn\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn import model_selection, naive_bayes, svm\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "import io\r\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1yoo0pPHfs",
        "outputId": "c63f49e1-48fd-46e4-8690-17e8d86123d7"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z45Qnw2Xu7eL"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAG5RCVC9pew"
      },
      "source": [
        "#import base64\r\n",
        "#import requests\r\n",
        "\r\n",
        "#master = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt\"\r\n",
        "#req = requests.get(master)\r\n",
        "#req = req.text\r\n",
        "#for line in req:\r\n",
        "#   print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RisVedtg0gEo"
      },
      "source": [
        "# from google.colab import files\r\n",
        "# uploaded= files.upload()\r\n",
        "# file= \"Train_Text.txt\"\r\n",
        "# uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "\r\n",
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_text.txt', allow_redirects= True)\r\n",
        "open('train_text.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/train_text.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data = file1.readlines()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1omFKZNL-R2r"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_labels.txt', allow_redirects= True)\r\n",
        "open('train_labels.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/train_labels.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data1 = file1.readlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnoyei5LtIuO"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt', allow_redirects= True)\r\n",
        "open('test_text.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/test_text.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data2 = file1.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsOfLjwQtMaE"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_labels.txt', allow_redirects= True)\r\n",
        "open('test_labels.txt', 'wb').write(r.content)\r\n",
        "example1 = \"/content/test_labels.txt\"\r\n",
        "with open(example1, \"r\") as file1:\r\n",
        "    data3 = file1.readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78VNicp0JDC"
      },
      "source": [
        "# data = uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data1 = uploaded1[file1].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data2 = uploaded2[file2].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "# data3 = uploaded3[file3].decode(\"utf-8\").split(\"\\r\\n\")\r\n",
        "\r\n",
        "data= [data[i].strip() for i in range(len(data))]\r\n",
        "data1= [data1[i].strip() for i in range(len(data1))]\r\n",
        "data2= [data2[i].strip() for i in range(len(data2))]\r\n",
        "data3= [data3[i].strip() for i in range(len(data3))]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWgZGMiHV2v"
      },
      "source": [
        "### df dataframe is training data\r\n",
        "\r\n",
        "df= pd.DataFrame()\r\n",
        "df['Text']=range(0, len(data))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNlc9edVFmS3",
        "outputId": "b3c8bd55-2dc9-4fb8-e2c8-e184a63836c7"
      },
      "source": [
        "for i in range(len(data)):\r\n",
        "  df.iloc[i, df.columns.get_loc('Text')]= data[i]\r\n",
        "print(df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text\n",
            "0  @user nice new signage. Are you not concerned ...\n",
            "1  A woman who you fucked multiple times saying y...\n",
            "2  @user @user real talk do you have eyes or were...\n",
            "3  your girlfriend lookin at me like a groupie in...\n",
            "4                        Hysterical woman like @user\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQzdmeOMhjJ"
      },
      "source": [
        "df['Label']=range(0, len(data))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_JzW3rwM5nf",
        "outputId": "b715fe00-699a-4d3f-db1f-27de838fe2f5"
      },
      "source": [
        "for i in range(len(data1)):\r\n",
        "  df.iloc[i, df.columns.get_loc('Label')]= data1[i]\r\n",
        "print(df.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user nice new signage. Are you not concerned ...     0\n",
            "1  A woman who you fucked multiple times saying y...     1\n",
            "2  @user @user real talk do you have eyes or were...     1\n",
            "3  your girlfriend lookin at me like a groupie in...     1\n",
            "4                        Hysterical woman like @user     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIFphT7NNElc"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\r\n",
        "df['Text'].dropna(inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ko_Sa_MNYGR"
      },
      "source": [
        "# Step - b : Change all the text to lower case.\r\n",
        "df['Text'] = [entry.lower() for entry in df['Text']]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fcKe9U0dN0ap",
        "outputId": "9ab9a976-ac00-4157-e38a-23fd01962651"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user nice new signage. are you not concerned ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a woman who you fucked multiple times saying y...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user real talk do you have eyes or were...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your girlfriend lookin at me like a groupie in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hysterical woman like @user</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label\n",
              "0  @user nice new signage. are you not concerned ...     0\n",
              "1  a woman who you fucked multiple times saying y...     1\n",
              "2  @user @user real talk do you have eyes or were...     1\n",
              "3  your girlfriend lookin at me like a groupie in...     1\n",
              "4                        hysterical woman like @user     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sULiTbrlN6-X"
      },
      "source": [
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\r\n",
        "df['Text']= [word_tokenize(entry) for entry in df['Text']]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3mTnI5pqPPKB",
        "outputId": "30362d74-b34b-4e23-aec1-597dc0ce3039"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label\n",
              "0  [@, user, nice, new, signage, ., are, you, not...     0\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...     1\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...     1\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...     1\n",
              "4                 [hysterical, woman, like, @, user]     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNO2bnB7PjUs"
      },
      "source": [
        "def preprocess(text):\r\n",
        "    new_text = []\r\n",
        "    for t in text.split(\" \"):\r\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\r\n",
        "        t = 'http' if t.startswith('http') else t\r\n",
        "        new_text.append(t)\r\n",
        "    return \" \".join(new_text)\r\n",
        "#df['Text']= [preprocess(entry) for entry in df['Text']]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEUE1JPqQfWA"
      },
      "source": [
        "for entry in df['Text']:\r\n",
        "  print(entry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQMsdLPrSNWb"
      },
      "source": [
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\r\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\r\n",
        "tag_map['J'] = wn.ADJ\r\n",
        "tag_map['V'] = wn.VERB\r\n",
        "tag_map['R'] = wn.ADV"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNVBzx_tTKjl"
      },
      "source": [
        "for index,entry in enumerate(df['Text']):\r\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\r\n",
        "    Final_words = []\r\n",
        "    # Initializing WordNetLemmatizer()\r\n",
        "    word_Lemmatized = WordNetLemmatizer()\r\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\r\n",
        "    for word, tag in pos_tag(entry):\r\n",
        "        # Below condition is to check for Stop words and consider only alphabets\r\n",
        "        if word not in stopwords.words('english') and word.isalpha():\r\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\r\n",
        "            Final_words.append(word_Final)\r\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\r\n",
        "    df.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NnCcgzWqTT0t",
        "outputId": "5a15d8c1-e511-4977-97ac-6c7611dfcbde"
      },
      "source": [
        "df.head()\r\n",
        "#print(df['Text_Final'].dtypes)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'nice', 'new', 'signage', 'concern', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['woman', 'fuck', 'multiple', 'time', 'say', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'real', 'talk', 'eye', 'gouge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>['girlfriend', 'lookin', 'like', 'groupie', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "      <td>['hysterical', 'woman', 'like', 'user']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, nice, new, signage, ., are, you, not...  ...  ['user', 'nice', 'new', 'signage', 'concern', ...\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...  ...  ['woman', 'fuck', 'multiple', 'time', 'say', '...\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...  ...  ['user', 'user', 'real', 'talk', 'eye', 'gouge...\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...  ...  ['girlfriend', 'lookin', 'like', 'groupie', 'b...\n",
              "4                 [hysterical, woman, like, @, user]  ...            ['hysterical', 'woman', 'like', 'user']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG7Da5n9naBQ"
      },
      "source": [
        "#df['Text_Final']= df['Text_Final'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmEIUOFoJA8",
        "outputId": "56a2483e-e6c1-43c1-c35b-92b360b729ce"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text          object\n",
            "Label         object\n",
            "Text_Final    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CWhanrYxvT8"
      },
      "source": [
        "### df1 dataframe is test data\r\n",
        "\r\n",
        "df1= pd.DataFrame()\r\n",
        "df1['Text']=range(0, len(data2))\r\n",
        "df1['Label']=range(0, len(data2))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLKRaQVjxWH-",
        "outputId": "63d0fc14-a40b-44cb-a15d-f0b74de533b3"
      },
      "source": [
        "for i in range(len(data2)):\r\n",
        "  df1.iloc[i, df1.columns.get_loc('Text')]= data2[i]\r\n",
        "print(df1.head())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text  Label\n",
            "0  @user , you are correct that Reid certainly is...      0\n",
            "1             Whoever just unfollowed me you a bitch      1\n",
            "2  @user @user Those People Invaded Us!!! They DO...      2\n",
            "3  stop JUDGING bitches by there cover, jus cuz s...      3\n",
            "4  how about i knock heads off and send them gift...      4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcjParajxiGG",
        "outputId": "7040313c-c909-4f56-a1f0-9d6512dead41"
      },
      "source": [
        "for i in range(len(data3)):\r\n",
        "  df1.iloc[i, df1.columns.get_loc('Label')]= data3[i]\r\n",
        "print(df1.head())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user , you are correct that Reid certainly is...     0\n",
            "1             Whoever just unfollowed me you a bitch     1\n",
            "2  @user @user Those People Invaded Us!!! They DO...     1\n",
            "3  stop JUDGING bitches by there cover, jus cuz s...     1\n",
            "4  how about i knock heads off and send them gift...     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW_ISkXexALh"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\r\n",
        "\r\n",
        "#df1['Text']= df1['Text'].astype(str)\r\n",
        "\r\n",
        "df1['Text'].dropna(inplace=True)\r\n",
        "\r\n",
        "# Step - b : Change all the text to lower case.\r\n",
        "df1['Text'] = [entry.lower() for entry in df1['Text']]\r\n",
        "\r\n",
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\r\n",
        "df1['Text']= [word_tokenize(entry) for entry in df1['Text']]\r\n",
        "\r\n",
        "for index,entry in enumerate(df1['Text']):\r\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\r\n",
        "    Final_words = []\r\n",
        "    # Initializing WordNetLemmatizer()\r\n",
        "    word_Lemmatized = WordNetLemmatizer()\r\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\r\n",
        "    for word, tag in pos_tag(entry):\r\n",
        "        # Below condition is to check for Stop words and consider only alphabets\r\n",
        "        if word not in stopwords.words('english') and word.isalpha():\r\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\r\n",
        "            Final_words.append(word_Final)\r\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\r\n",
        "    df1.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NLnug3v71yLm",
        "outputId": "0ccbf3bc-ef31-45fa-9511-72d8a487c82d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'nice', 'new', 'signage', 'concern', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['woman', 'fuck', 'multiple', 'time', 'say', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'real', 'talk', 'eye', 'gouge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>['girlfriend', 'lookin', 'like', 'groupie', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "      <td>['hysterical', 'woman', 'like', 'user']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, nice, new, signage, ., are, you, not...  ...  ['user', 'nice', 'new', 'signage', 'concern', ...\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...  ...  ['woman', 'fuck', 'multiple', 'time', 'say', '...\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...  ...  ['user', 'user', 'real', 'talk', 'eye', 'gouge...\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...  ...  ['girlfriend', 'lookin', 'like', 'groupie', 'b...\n",
              "4                 [hysterical, woman, like, @, user]  ...            ['hysterical', 'woman', 'like', 'user']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XXmy5uss11ld",
        "outputId": "9c647a09-f745-4ea1-d1b5-c8feff68b3c7"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, ,, you, are, correct, that, reid, ce...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'correct', 'reid', 'certainly', 'weas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[whoever, just, unfollowed, me, you, a, bitch]</td>\n",
              "      <td>1</td>\n",
              "      <td>['whoever', 'unfollowed', 'bitch']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, those, people, invaded, us,...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'people', 'invade', 'u', 'bel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[stop, judging, bitches, by, there, cover, ,, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['stop', 'judging', 'bitch', 'cover', 'jus', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[how, about, i, knock, heads, off, and, send, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['knock', 'head', 'send', 'gift', 'wrap', 'mom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, ,, you, are, correct, that, reid, ce...  ...  ['user', 'correct', 'reid', 'certainly', 'weas...\n",
              "1     [whoever, just, unfollowed, me, you, a, bitch]  ...                 ['whoever', 'unfollowed', 'bitch']\n",
              "2  [@, user, @, user, those, people, invaded, us,...  ...  ['user', 'user', 'people', 'invade', 'u', 'bel...\n",
              "3  [stop, judging, bitches, by, there, cover, ,, ...  ...  ['stop', 'judging', 'bitch', 'cover', 'jus', '...\n",
              "4  [how, about, i, knock, heads, off, and, send, ...  ...  ['knock', 'head', 'send', 'gift', 'wrap', 'mom...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0WvjkezXLX2",
        "outputId": "5bf8a0c7-de69-4190-c4cf-34a92533aa9b"
      },
      "source": [
        "t_df= pd.concat([df, df1])\r\n",
        "\r\n",
        "#Tfidf_vect = TfidfVectorizer(max_features=5000)\r\n",
        "Tfidf_vect = TfidfVectorizer(max_features=6000)\r\n",
        "Tfidf_vect.fit(t_df['Text_Final'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=6000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwSwVLz45gpc",
        "outputId": "ef813139-32e1-4ddc-b7eb-13745f062055"
      },
      "source": [
        "t_df['Label'].value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6935\n",
              "1    5035\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mK4jl99rPyU"
      },
      "source": [
        "Train_X= df['Text_Final']\r\n",
        "Train_Y= df['Label']"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvF8xPP_q_1S"
      },
      "source": [
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\r\n",
        "print(Train_X_Tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ncTyoHuzCPs"
      },
      "source": [
        "# df1['Text_Final']= df1['Text_Final'].astype(str)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX1FP5ouzcWA"
      },
      "source": [
        "Test_X= df1['Text_Final']\r\n",
        "Test_Y= df1['Label']\r\n",
        "\r\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW863mYg0epV",
        "outputId": "be665890-c7a8-4fa6-cdc8-28b95437217f"
      },
      "source": [
        "print(Test_X[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user', 'correct', 'reid', 'certainly', 'weasel', 'sadly', 'get', 'weasel', 'user', 'sen', 'mcconnell', 'user', 'corrupt', 'mueller', 'investigation', 'stop', 'maga', 'kag', 'potus', 'trump', 'news', 'votered', 'nodaca', 'usa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOtVjLqj5DYS",
        "outputId": "cdb15db1-681c-4e49-daaa-65d3c6dbcb23"
      },
      "source": [
        "print(Train_X_Tfidf[4,:])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5889)\t0.46093703537618935\n",
            "  (0, 5617)\t0.2704545435932169\n",
            "  (0, 3138)\t0.4977275351310296\n",
            "  (0, 2477)\t0.6831242127466892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-yDowB74-if",
        "outputId": "be7af124-6d61-4ffc-bbcc-0a6e588bebe9"
      },
      "source": [
        "print(Test_X_Tfidf[0,:])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5776)\t0.5245332284741525\n",
            "  (0, 5703)\t0.17062117197968327\n",
            "  (0, 5617)\t0.16695067668810973\n",
            "  (0, 5611)\t0.15011967841622545\n",
            "  (0, 5498)\t0.11631704220011843\n",
            "  (0, 5137)\t0.12776557001344474\n",
            "  (0, 4780)\t0.2557668983516498\n",
            "  (0, 4644)\t0.23864587334059517\n",
            "  (0, 4399)\t0.26226661423707626\n",
            "  (0, 4087)\t0.16681008163991645\n",
            "  (0, 3613)\t0.1307148844684054\n",
            "  (0, 3581)\t0.15689180203550454\n",
            "  (0, 3498)\t0.23280074584597032\n",
            "  (0, 3339)\t0.22012081955500767\n",
            "  (0, 3252)\t0.11597918306390662\n",
            "  (0, 2888)\t0.15374477432452438\n",
            "  (0, 2730)\t0.22577618769753582\n",
            "  (0, 2114)\t0.09903464305038297\n",
            "  (0, 1205)\t0.2139658172492953\n",
            "  (0, 1200)\t0.2139658172492953\n",
            "  (0, 943)\t0.2504562437888357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4LqK_On5NPY",
        "outputId": "ca790618-990a-4aea-dd52-11ce44ce660c"
      },
      "source": [
        "print(Test_X_Tfidf[2,:])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5966)\t0.2996560659095236\n",
            "  (0, 5617)\t0.20059381923158565\n",
            "  (0, 4550)\t0.23515538642922806\n",
            "  (0, 3951)\t0.21306982003758032\n",
            "  (0, 3754)\t0.2883321128418398\n",
            "  (0, 3613)\t0.23558393196797703\n",
            "  (0, 2722)\t0.35050206768008074\n",
            "  (0, 2534)\t0.2895207644595778\n",
            "  (0, 2506)\t0.38084915294360816\n",
            "  (0, 2423)\t0.2972802515761778\n",
            "  (0, 991)\t0.3370251647496475\n",
            "  (0, 207)\t0.2774072856361166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Hd-_B2zUvt",
        "outputId": "0eba4d1b-6d3e-4c90-e8c2-3c0505c85250"
      },
      "source": [
        "# fit the training dataset on the NB classifier\r\n",
        "Naive = naive_bayes.MultinomialNB()\r\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  52.996632996633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S0jHE7p2xuf",
        "outputId": "031831ba-f412-495a-e3d1-4f10cfefdd1a"
      },
      "source": [
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes F1 Score ->  50.96879359287348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCa7ijTJ0x-I",
        "outputId": "f3c748aa-1112-42d7-b431-973e54a88459"
      },
      "source": [
        "# Classifier - Algorithm - SVM\r\n",
        "# fit the training dataset on the classifier\r\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\r\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  51.27946127946128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLdB9AN48ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9bc94bf-1e61-4a60-f12b-447b9a1a2dfb"
      },
      "source": [
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM F1 Score ->  47.97042917837131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MYH1rs0ejN",
        "outputId": "f734ff0f-61d7-4e10-fd3d-599cf3b0a709"
      },
      "source": [
        "print(predictions_NB[0:4])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbwajj6f1QEv",
        "outputId": "c91f13ca-85c7-49cb-a745-0677ed246c33"
      },
      "source": [
        "print(predictions_SVM[0:4])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZEkGK2hScrI",
        "outputId": "19084ef1-0d93-4e95-f56e-08c2992c2324"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "parameters = {  \r\n",
        "'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)  \r\n",
        "}  \r\n",
        "grid_1= GridSearchCV(Naive, parameters)\r\n",
        "grid_1.fit(Train_X_Tfidf,Train_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 1e-05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ycfcSAiScur",
        "outputId": "027033f8-e014-4a7c-942e-06aad0d0fd7f"
      },
      "source": [
        "# print best parameter after tuning \r\n",
        "print(grid_1.best_params_) \r\n",
        "  \r\n",
        "# print how our model looks after hyper-parameter tuning \r\n",
        "print(grid_1.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1}\n",
            "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVlF8KFS_9s",
        "outputId": "c8b7f9e7-6ca5-47fa-97d7-47cfa4dfafc3"
      },
      "source": [
        "# fit the training dataset on the NB classifier\r\n",
        "Naive = naive_bayes.MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\r\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\r\n",
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  52.996632996633\n",
            "Naive Bayes F1 Score ->  50.96879359287348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJiEja_mJTdm",
        "outputId": "35b5a9c8-ef7c-484d-970e-7fee36fb7b2d"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \r\n",
        "  \r\n",
        "# defining parameter range \r\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \r\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "              'kernel': ['rbf']}  \r\n",
        "  \r\n",
        "grid = GridSearchCV(SVM, param_grid, refit = True, verbose = 3) \r\n",
        " \r\n",
        "# fitting the model for grid search \r\n",
        "grid.fit(Train_X_Tfidf,Train_Y) \r\n",
        "\r\n",
        "# print best parameter after tuning \r\n",
        "print(grid.best_params_) \r\n",
        "  \r\n",
        "# print how our model looks after hyper-parameter tuning \r\n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.617, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.614, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.612, total=   8.5s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.611, total=   8.4s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.618, total=   8.5s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.582, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   8.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.770, total=   8.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.781, total=   8.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.785, total=   8.4s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.768, total=   8.2s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.771, total=   8.3s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.744, total=   7.5s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.750, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.746, total=   7.4s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.584, total=   8.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.586, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   8.0s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.0s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.775, total=   9.5s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.771, total=   9.3s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.3s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.3s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.764, total=   6.9s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.762, total=   6.9s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.747, total=   6.8s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.4s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.750, total=   7.3s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.585, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.583, total=   8.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.586, total=   8.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   8.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   8.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.777, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.769, total=   9.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.3s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.723, total=  11.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.731, total=  10.3s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.718, total=  10.1s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.721, total=  11.7s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.729, total=  10.2s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.753, total=   6.8s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.759, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.760, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.754, total=   6.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.749, total=   6.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.759, total=   7.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.758, total=   7.3s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.3s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.752, total=   7.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.585, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.583, total=   8.3s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.586, total=   8.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.770, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.777, total=   9.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.769, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.722, total=  12.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.726, total=  10.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.718, total=  10.5s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.719, total=  10.4s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.724, total=  10.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.721, total=   9.2s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.726, total=   9.3s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.712, total=   9.1s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.706, total=   9.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.713, total=   9.2s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.752, total=   6.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.758, total=   6.7s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.757, total=   6.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.754, total=   6.7s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.748, total=   6.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.759, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.758, total=   7.5s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.4s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.752, total=   7.4s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 17.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
            "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIjmsiQ-P2Z5",
        "outputId": "b2acb740-5510-471c-fd8c-3e00aab9bfe7"
      },
      "source": [
        "# Classifier - Algorithm - SVM\r\n",
        "# fit the training dataset on the classifier\r\n",
        "SVM = svm.SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\r\n",
        "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\r\n",
        "    probability=False, random_state=None, shrinking=True, tol=0.001,\r\n",
        "    verbose=False)\r\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\r\n",
        "# predict the labels on validation dataset\r\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\r\n",
        "# Use accuracy_score function to get the accuracy\r\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\r\n",
        "\r\n",
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  51.07744107744108\n",
            "SVM F1 Score ->  48.03177142799339\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}