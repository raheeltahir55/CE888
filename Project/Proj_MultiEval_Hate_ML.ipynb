{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj_MultiEval_Hate_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQgz0kZwnGIP3ZFu8EE+WZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheeltahir55/CE888/blob/main/Project/Proj_MultiEval_Hate_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkyENKK0qsMJ"
      },
      "source": [
        "### HATE ####\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "import io\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1yoo0pPHfs",
        "outputId": "1819ede3-e22f-4d6a-d1de-775f1cd35a48"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z45Qnw2Xu7eL"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAG5RCVC9pew"
      },
      "source": [
        "#import base64\n",
        "#import requests\n",
        "\n",
        "#master = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt\"\n",
        "#req = requests.get(master)\n",
        "#req = req.text\n",
        "#for line in req:\n",
        "#   print(line)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RisVedtg0gEo"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded= files.upload()\n",
        "# file= \"Train_Text.txt\"\n",
        "# uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "\n",
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_text.txt', allow_redirects= True)\n",
        "open('train_text.txt', 'wb').write(r.content)\n",
        "example1 = \"/content/train_text.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data = file1.readlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1omFKZNL-R2r"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/train_labels.txt', allow_redirects= True)\n",
        "open('train_labels.txt', 'wb').write(r.content)\n",
        "example1 = \"/content/train_labels.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data1 = file1.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnoyei5LtIuO"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_text.txt', allow_redirects= True)\n",
        "open('test_text.txt', 'wb').write(r.content)\n",
        "example1 = \"/content/test_text.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data2 = file1.readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsOfLjwQtMaE"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/test_labels.txt', allow_redirects= True)\n",
        "open('test_labels.txt', 'wb').write(r.content)\n",
        "example1 = \"/content/test_labels.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data3 = file1.readlines()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8vmjVZEJT4"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_text.txt', allow_redirects= True)\n",
        "open('val_text.txt', 'wb').write(r.content)\n",
        "example1 = \"./val_text.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data4 = file1.readlines()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilsCNDrlEKD6"
      },
      "source": [
        "r= requests.get('https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/val_labels.txt', allow_redirects= True)\n",
        "open('val_labels.txt', 'wb').write(r.content)\n",
        "example1 = \"./val_labels.txt\"\n",
        "with open(example1, \"r\") as file1:\n",
        "    data5 = file1.readlines()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k78VNicp0JDC"
      },
      "source": [
        "# data = uploaded[file].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "# data1 = uploaded1[file1].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "# data2 = uploaded2[file2].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "# data3 = uploaded3[file3].decode(\"utf-8\").split(\"\\r\\n\")\n",
        "\n",
        "data= [data[i].strip() for i in range(len(data))]\n",
        "data1= [data1[i].strip() for i in range(len(data1))]\n",
        "data2= [data2[i].strip() for i in range(len(data2))]\n",
        "data3= [data3[i].strip() for i in range(len(data3))]\n",
        "data4= [data4[i].strip() for i in range(len(data4))]\n",
        "data5= [data5[i].strip() for i in range(len(data5))]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWgZGMiHV2v"
      },
      "source": [
        "### df dataframe is training data\n",
        "\n",
        "df= pd.DataFrame()\n",
        "df['Text']=range(0, len(data))\n",
        "df['Label']=range(0, len(data))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNlc9edVFmS3",
        "outputId": "31e85248-ee93-4421-c170-50f30ec7931c"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  df.iloc[i, df.columns.get_loc('Text')]= data[i]\n",
        "for i in range(len(data1)):\n",
        "  df.iloc[i, df.columns.get_loc('Label')]= data1[i]\n",
        "print(df.head())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user nice new signage. Are you not concerned ...     0\n",
            "1  A woman who you fucked multiple times saying y...     1\n",
            "2  @user @user real talk do you have eyes or were...     1\n",
            "3  your girlfriend lookin at me like a groupie in...     1\n",
            "4                        Hysterical woman like @user     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUHvh2BuF1wj",
        "outputId": "fd4f39a9-4816-4353-f354-57418ebd1242"
      },
      "source": [
        "### df1 dataframe is test data\n",
        "\n",
        "df1= pd.DataFrame()\n",
        "df1['Text']=range(0, len(data2))\n",
        "df1['Label']=range(0, len(data2))\n",
        "for i in range(len(data2)):\n",
        "  df1.iloc[i, df1.columns.get_loc('Text')]= data2[i]\n",
        "for i in range(len(data3)):\n",
        "  df1.iloc[i, df1.columns.get_loc('Label')]= data3[i]\n",
        "print(df1.head())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text Label\n",
            "0  @user , you are correct that Reid certainly is...     0\n",
            "1             Whoever just unfollowed me you a bitch     1\n",
            "2  @user @user Those People Invaded Us!!! They DO...     1\n",
            "3  stop JUDGING bitches by there cover, jus cuz s...     1\n",
            "4  how about i knock heads off and send them gift...     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7iw-lMqRFzeY",
        "outputId": "697c0570-934e-4e12-93d2-6f3e0320eab5"
      },
      "source": [
        "## df2 is dataframe for validation\n",
        "\n",
        "df2= pd.DataFrame()\n",
        "df2['Text']=range(0, len(data4))\n",
        "df2['Label']=range(0, len(data4))\n",
        "for index in range(len(data4)):\n",
        "  df2.loc[index, 'Text']=data4[index]\n",
        "for index in range(len(data5)):\n",
        "  df2.loc[index, 'Label']=data5[index]\n",
        "df2.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user If book Claire wanted to \"stay in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>After arriving in the EU refugees make protest...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ðŸ˜³ðŸ‘‡</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@user Worst thing is if they are that stupid t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Say's the HYSTERICAL woman. It is woman ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label\n",
              "0  @user @user If book Claire wanted to \"stay in ...     0\n",
              "1  After arriving in the EU refugees make protest...     0\n",
              "2                                                 ðŸ˜³ðŸ‘‡     0\n",
              "3  @user Worst thing is if they are that stupid t...     1\n",
              "4  @user Say's the HYSTERICAL woman. It is woman ...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFAHpXjBGNrx",
        "outputId": "dc331e6f-3031-4bc3-f428-455eddb79b93"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWrmDsHCGZnX"
      },
      "source": [
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNO2bnB7PjUs"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Step - b : Change all the text to lower case.\n",
        "df['Text'] = [entry.lower() for entry in df['Text']]\n",
        "\n",
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "df['Text']= [word_tokenize(entry) for entry in df['Text']]\n",
        "\n",
        "for index,entry in enumerate(df['Text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    df.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NnCcgzWqTT0t",
        "outputId": "1d0bb3c0-e93b-4cdc-8dbc-cb6256a05c96"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, nice, new, signage, ., are, you, not...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'nice', 'new', 'signage', 'concern', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[a, woman, who, you, fucked, multiple, times, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['woman', 'fuck', 'multiple', 'time', 'say', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, real, talk, do, you, have, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'real', 'talk', 'eye', 'gouge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[your, girlfriend, lookin, at, me, like, a, gr...</td>\n",
              "      <td>1</td>\n",
              "      <td>['girlfriend', 'lookin', 'like', 'groupie', 'b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hysterical, woman, like, @, user]</td>\n",
              "      <td>0</td>\n",
              "      <td>['hysterical', 'woman', 'like', 'user']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, nice, new, signage, ., are, you, not...  ...  ['user', 'nice', 'new', 'signage', 'concern', ...\n",
              "1  [a, woman, who, you, fucked, multiple, times, ...  ...  ['woman', 'fuck', 'multiple', 'time', 'say', '...\n",
              "2  [@, user, @, user, real, talk, do, you, have, ...  ...  ['user', 'user', 'real', 'talk', 'eye', 'gouge...\n",
              "3  [your, girlfriend, lookin, at, me, like, a, gr...  ...  ['girlfriend', 'lookin', 'like', 'groupie', 'b...\n",
              "4                 [hysterical, woman, like, @, user]  ...            ['hysterical', 'woman', 'like', 'user']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmEIUOFoJA8",
        "outputId": "187d1420-9767-4996-8778-447f0d24b72a"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text          object\n",
            "Label         object\n",
            "Text_Final    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW_ISkXexALh"
      },
      "source": [
        "# Step - a : Remove blank rows if any.\n",
        "\n",
        "df1.dropna(inplace=True)\n",
        "\n",
        "# Step - b : Change all the text to lower case.\n",
        "df1['Text'] = [entry.lower() for entry in df1['Text']]\n",
        "\n",
        "# Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
        "df1['Text']= [word_tokenize(entry) for entry in df1['Text']]\n",
        "\n",
        "for index,entry in enumerate(df1['Text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    df1.loc[index,'Text_Final'] = str(Final_words) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "NLnug3v71yLm",
        "outputId": "27e48237-b5a9-4d9e-eca7-7f8628613861"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>Text_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, user, ,, you, are, correct, that, reid, ce...</td>\n",
              "      <td>0</td>\n",
              "      <td>['user', 'correct', 'reid', 'certainly', 'weas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[whoever, just, unfollowed, me, you, a, bitch]</td>\n",
              "      <td>1</td>\n",
              "      <td>['whoever', 'unfollowed', 'bitch']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, user, @, user, those, people, invaded, us,...</td>\n",
              "      <td>1</td>\n",
              "      <td>['user', 'user', 'people', 'invade', 'u', 'bel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[stop, judging, bitches, by, there, cover, ,, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['stop', 'judging', 'bitch', 'cover', 'jus', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[how, about, i, knock, heads, off, and, send, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>['knock', 'head', 'send', 'gift', 'wrap', 'mom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         Text_Final\n",
              "0  [@, user, ,, you, are, correct, that, reid, ce...  ...  ['user', 'correct', 'reid', 'certainly', 'weas...\n",
              "1     [whoever, just, unfollowed, me, you, a, bitch]  ...                 ['whoever', 'unfollowed', 'bitch']\n",
              "2  [@, user, @, user, those, people, invaded, us,...  ...  ['user', 'user', 'people', 'invade', 'u', 'bel...\n",
              "3  [stop, judging, bitches, by, there, cover, ,, ...  ...  ['stop', 'judging', 'bitch', 'cover', 'jus', '...\n",
              "4  [how, about, i, knock, heads, off, and, send, ...  ...  ['knock', 'head', 'send', 'gift', 'wrap', 'mom...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0WvjkezXLX2",
        "outputId": "328ea2ad-d602-4e7d-a512-ddf985de5a2c"
      },
      "source": [
        "t_df= pd.concat([df, df1])\n",
        "\n",
        "#Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect = TfidfVectorizer(max_features=6000)\n",
        "Tfidf_vect.fit(t_df['Text_Final'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=6000,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwSwVLz45gpc",
        "outputId": "7fba496f-7a72-4122-e6ab-ed5c133c6615"
      },
      "source": [
        "t_df['Label'].value_counts()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6935\n",
              "1    5035\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mK4jl99rPyU"
      },
      "source": [
        "Train_X= df['Text_Final']\n",
        "Train_Y= df['Label']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvF8xPP_q_1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeccba3a-66f3-417c-d0d1-8a37e91fc87d"
      },
      "source": [
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "print(Train_X_Tfidf)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5617)\t0.1344346568489373\n",
            "  (0, 3591)\t0.4395753531836085\n",
            "  (0, 3580)\t0.3323894931367614\n",
            "  (0, 2477)\t0.33956008986090064\n",
            "  (0, 1261)\t0.5623784641576471\n",
            "  (0, 1102)\t0.49663614970020475\n",
            "  (1, 5971)\t0.2867411187726667\n",
            "  (1, 5889)\t0.15820637673835744\n",
            "  (1, 5395)\t0.20682714198364757\n",
            "  (1, 5082)\t0.3929547142306144\n",
            "  (1, 4979)\t0.3465293137116392\n",
            "  (1, 4697)\t0.18688152249162115\n",
            "  (1, 3502)\t0.38832388192192946\n",
            "  (1, 2967)\t0.20268743172041367\n",
            "  (1, 2353)\t0.300537083648912\n",
            "  (1, 2057)\t0.18577565479656125\n",
            "  (1, 1458)\t0.2355971597226318\n",
            "  (1, 1093)\t0.41028446701757687\n",
            "  (2, 5617)\t0.3039830760717317\n",
            "  (2, 5278)\t0.405482226663496\n",
            "  (2, 4317)\t0.44184026909179663\n",
            "  (2, 4284)\t0.4789788275750967\n",
            "  (2, 1841)\t0.564388972842007\n",
            "  (3, 3198)\t0.5558986883496702\n",
            "  (3, 3138)\t0.24455446492416016\n",
            "  :\t:\n",
            "  (8998, 5551)\t0.29590378663089417\n",
            "  (8998, 4255)\t0.3251918131802601\n",
            "  (8998, 4107)\t0.3171326311143806\n",
            "  (8998, 4050)\t0.2218189042493167\n",
            "  (8998, 3758)\t0.31054779990557707\n",
            "  (8998, 3403)\t0.19704369953388434\n",
            "  (8998, 3321)\t0.21155803015346364\n",
            "  (8998, 3263)\t0.2729340470499673\n",
            "  (8998, 2805)\t0.29590378663089417\n",
            "  (8998, 1394)\t0.28865624727566147\n",
            "  (8998, 1217)\t0.1495322904175029\n",
            "  (8998, 195)\t0.1942930115987338\n",
            "  (8999, 5617)\t0.08704223846703643\n",
            "  (8999, 5024)\t0.2466334542944653\n",
            "  (8999, 4764)\t0.2090298448087412\n",
            "  (8999, 3523)\t0.2715048254567651\n",
            "  (8999, 2911)\t0.42331637140034256\n",
            "  (8999, 2330)\t0.34999216310498255\n",
            "  (8999, 2124)\t0.4064448356698622\n",
            "  (8999, 2057)\t0.1741976090904823\n",
            "  (8999, 1065)\t0.3076435346045482\n",
            "  (8999, 682)\t0.27789935118024817\n",
            "  (8999, 649)\t0.1174815237598755\n",
            "  (8999, 601)\t0.2715048254567651\n",
            "  (8999, 468)\t0.23992580780466283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX1FP5ouzcWA"
      },
      "source": [
        "Test_X= df1['Text_Final']\n",
        "Test_Y= df1['Label']\n",
        "\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW863mYg0epV",
        "outputId": "90b9992c-2274-48fe-c04c-002e6ce6522a"
      },
      "source": [
        "print(Test_X[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user', 'correct', 'reid', 'certainly', 'weasel', 'sadly', 'get', 'weasel', 'user', 'sen', 'mcconnell', 'user', 'corrupt', 'mueller', 'investigation', 'stop', 'maga', 'kag', 'potus', 'trump', 'news', 'votered', 'nodaca', 'usa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOtVjLqj5DYS",
        "outputId": "3e766c12-40eb-4335-a426-b8ecd0d31393"
      },
      "source": [
        "print(Train_X_Tfidf[4,:])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5889)\t0.46093703537618935\n",
            "  (0, 5617)\t0.2704545435932169\n",
            "  (0, 3138)\t0.4977275351310296\n",
            "  (0, 2477)\t0.6831242127466892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-yDowB74-if",
        "outputId": "f1ec2920-6482-4bfa-d39f-db7114ea95ab"
      },
      "source": [
        "print(Test_X_Tfidf[0,:])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5776)\t0.5245332284741525\n",
            "  (0, 5703)\t0.17062117197968327\n",
            "  (0, 5617)\t0.16695067668810973\n",
            "  (0, 5611)\t0.15011967841622545\n",
            "  (0, 5498)\t0.11631704220011843\n",
            "  (0, 5137)\t0.12776557001344474\n",
            "  (0, 4780)\t0.2557668983516498\n",
            "  (0, 4644)\t0.23864587334059517\n",
            "  (0, 4399)\t0.26226661423707626\n",
            "  (0, 4087)\t0.16681008163991645\n",
            "  (0, 3613)\t0.1307148844684054\n",
            "  (0, 3581)\t0.15689180203550454\n",
            "  (0, 3498)\t0.23280074584597032\n",
            "  (0, 3339)\t0.22012081955500767\n",
            "  (0, 3252)\t0.11597918306390662\n",
            "  (0, 2888)\t0.15374477432452438\n",
            "  (0, 2730)\t0.22577618769753582\n",
            "  (0, 2114)\t0.09903464305038297\n",
            "  (0, 1205)\t0.2139658172492953\n",
            "  (0, 1200)\t0.2139658172492953\n",
            "  (0, 943)\t0.2504562437888357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4LqK_On5NPY",
        "outputId": "acf342a3-fbc5-4901-fd56-bc82ddd5aef1"
      },
      "source": [
        "print(Test_X_Tfidf[2,:])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5966)\t0.2996560659095236\n",
            "  (0, 5617)\t0.20059381923158565\n",
            "  (0, 4550)\t0.23515538642922806\n",
            "  (0, 3951)\t0.21306982003758032\n",
            "  (0, 3754)\t0.2883321128418398\n",
            "  (0, 3613)\t0.23558393196797703\n",
            "  (0, 2722)\t0.35050206768008074\n",
            "  (0, 2534)\t0.2895207644595778\n",
            "  (0, 2506)\t0.38084915294360816\n",
            "  (0, 2423)\t0.2972802515761778\n",
            "  (0, 991)\t0.3370251647496475\n",
            "  (0, 207)\t0.2774072856361166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Hd-_B2zUvt",
        "outputId": "abfb574c-9e9c-48b5-b271-78c35e4a8e83"
      },
      "source": [
        "# fit the training dataset on the NB classifier\n",
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  52.996632996633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S0jHE7p2xuf",
        "outputId": "f5aee036-fe71-4e1b-a384-69cf664e80a6"
      },
      "source": [
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes F1 Score ->  50.96879359287348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCa7ijTJ0x-I",
        "outputId": "08b5d2b9-1554-43a0-ffab-d0a73348dc55"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  51.27946127946128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLdB9AN48ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17c83c5-ac76-4e8a-dc92-9dab9bc39965"
      },
      "source": [
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM F1 Score ->  47.97042917837131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MYH1rs0ejN",
        "outputId": "a1d00e8c-db4f-459a-9b83-af2e91c516e8"
      },
      "source": [
        "print(predictions_NB[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbwajj6f1QEv",
        "outputId": "6a2c326e-e1ac-4b25-82df-273e4160cd94"
      },
      "source": [
        "print(predictions_SVM[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZEkGK2hScrI",
        "outputId": "19084ef1-0d93-4e95-f56e-08c2992c2324"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {  \n",
        "'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)  \n",
        "}  \n",
        "grid_1= GridSearchCV(Naive, parameters)\n",
        "grid_1.fit(Train_X_Tfidf,Train_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 1e-05)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ycfcSAiScur",
        "outputId": "027033f8-e014-4a7c-942e-06aad0d0fd7f"
      },
      "source": [
        "# print best parameter after tuning \n",
        "print(grid_1.best_params_) \n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning \n",
        "print(grid_1.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1}\n",
            "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVlF8KFS_9s",
        "outputId": "131c3454-9d90-40d5-c422-577cd9451522"
      },
      "source": [
        "# fit the training dataset on the NB classifier\n",
        "Naive = naive_bayes.MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
        "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  52.996632996633\n",
            "Naive Bayes F1 Score ->  50.96879359287348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJiEja_mJTdm",
        "outputId": "c00265e6-7412-465d-f0bc-628a503a8587"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "  \n",
        "# defining parameter range \n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "              'kernel': ['rbf']}  \n",
        "  \n",
        "grid = GridSearchCV(SVM, param_grid, refit = True, verbose = 3) \n",
        " \n",
        "# fitting the model for grid search \n",
        "grid.fit(Train_X_Tfidf,Train_Y) \n",
        "\n",
        "# print best parameter after tuning \n",
        "print(grid.best_params_) \n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning \n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.617, total=   8.3s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.614, total=   8.2s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   16.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.612, total=   8.2s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.611, total=   8.2s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.618, total=   8.2s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   7.9s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.582, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.581, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.579, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.8s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.6s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.770, total=   8.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.781, total=   8.1s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.785, total=   8.2s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.768, total=   8.0s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.771, total=   8.0s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.751, total=   7.2s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.744, total=   7.2s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.750, total=   7.2s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.746, total=   7.1s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.752, total=   7.2s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   7.8s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.584, total=   7.9s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   7.9s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.583, total=   7.9s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.586, total=   7.9s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   7.8s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.580, total=   7.8s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   7.8s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   7.8s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.579, total=   7.8s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.580, total=   7.8s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.579, total=   7.7s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.770, total=   9.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.775, total=   9.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.771, total=   9.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.0s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.764, total=   9.0s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.6s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.764, total=   6.6s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.762, total=   6.6s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.756, total=   6.6s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.747, total=   6.6s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.1s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.751, total=   7.1s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.757, total=   7.1s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.750, total=   7.1s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.752, total=   7.2s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.585, total=   8.1s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.584, total=   8.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.583, total=   8.0s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.586, total=   7.9s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   7.9s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.580, total=   8.0s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.579, total=   7.9s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.770, total=   9.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.777, total=   9.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.769, total=   9.0s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.1s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.763, total=   9.2s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.723, total=  11.4s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.731, total=   9.9s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.718, total=   9.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.721, total=  11.4s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.729, total=  10.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.753, total=   6.5s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.759, total=   6.5s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.760, total=   6.5s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.754, total=   6.5s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.749, total=   6.5s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.759, total=   7.2s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.2s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.758, total=   7.1s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.751, total=   7.1s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.752, total=   7.2s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.585, total=   8.1s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.584, total=   8.1s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.583, total=   8.1s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.586, total=   8.0s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.770, total=   9.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.777, total=   9.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.769, total=   9.2s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.1s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.763, total=   9.1s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.722, total=  11.7s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.726, total=  10.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.718, total=  10.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.719, total=  10.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.724, total=  10.2s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.721, total=   9.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.726, total=   9.2s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.712, total=   8.9s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.706, total=   9.2s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.713, total=   9.1s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.752, total=   6.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.758, total=   6.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.757, total=   6.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.754, total=   6.6s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.748, total=   6.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.759, total=   7.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.758, total=   7.3s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.751, total=   7.2s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.752, total=   7.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed: 16.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
            "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIjmsiQ-P2Z5",
        "outputId": "d743db25-7f2c-4e25-b313-9f636d4c7e71"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
        "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
        "    verbose=False)\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "\n",
        "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y, average='macro')*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  51.07744107744108\n",
            "SVM F1 Score ->  48.03177142799339\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}