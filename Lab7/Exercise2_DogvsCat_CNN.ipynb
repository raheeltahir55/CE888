{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise2_DogvsCat_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raheeltahir55/CE888/blob/main/Lab7/Exercise2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTh9DiKVslsJ"
      },
      "source": [
        "## Dogs vs. Cats \n",
        "\n",
        "In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n",
        "\n",
        "Ref: https://medium.com/@thegrigorian/rolling-in-the-deep-cnn-c8d3f7108c8c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSBI-_mSSY1g"
      },
      "source": [
        "Get your API Key from Kaggle using following steps:\n",
        "1. Login to [Kaggle](https://www.kaggle.com/) or Register if you don't have account\n",
        "2. Open Dataset (https://www.kaggle.com/c/dogs-vs-cats/rules) and accept terms and condition. \n",
        "3. On the top right corner click on your Icon and go to accounts and press a button \"Create New API Token\". It will download a JSON file containing your username and key. \n",
        "4. Now, paste both below. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEuZaWjJKtK_",
        "outputId": "8505ba14-549e-433e-c905-7a9ee17572d1"
      },
      "source": [
        "pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXSOc0tZIGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf8383e-c68d-4b53-9289-3b986af5ec44"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"raheeltahir\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"8cadaf2fe78e0159e6535cc7a2cc5bc4\" # key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle (https://www.kaggle.com/c/dogs-vs-cats/data)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 68.2MB/s]\n",
            "Downloading test1.zip to /content\n",
            " 97% 263M/271M [00:01<00:00, 158MB/s]\n",
            "100% 271M/271M [00:01<00:00, 192MB/s]\n",
            "Downloading train.zip to /content\n",
            " 97% 528M/543M [00:02<00:00, 266MB/s]\n",
            "100% 543M/543M [00:03<00:00, 186MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwIL8d1n7eS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe93e2d-8203-4fc4-82ed-01644c9992b8"
      },
      "source": [
        "# Unzip training data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/train.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa2Bj5i7pPKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b0ac62-2ce1-41cc-e811-0e9d946f0fe2"
      },
      "source": [
        "# Get all the paths\n",
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ERlHkfHqpK8"
      },
      "source": [
        "# Make new base directory\n",
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "os.mkdir(base_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANB1UJ6rQhM"
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULRgL9s9rV8T"
      },
      "source": [
        "import shutil\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3XAbIyr7vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a310539-c51a-4aaf-8e02-098a2b135de1"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yTA21_r-ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703eb464-33a9-4645-f024-f3fc74e73ad6"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mG8wekxsBVS"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zS4Klm8qWp6"
      },
      "source": [
        "## Using ImageDataGenerator to read images from directories\n",
        "As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RGB grids of pixels.\n",
        "* Convert these into floating-point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ7XU7t9sEh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be28a869-fd06-4130-8a9d-1f21e63faf67"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgLywySqm4u"
      },
      "source": [
        "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the generator—that is, after having run for `steps_per_epoch` gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
        "\n",
        "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMyfPphJsJG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175cf5bb-306b-4452-ac6e-17f7adc8f128"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 39s 75ms/step - loss: 0.6930 - acc: 0.5332 - val_loss: 0.6735 - val_acc: 0.5800\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.6680 - acc: 0.5747 - val_loss: 0.6303 - val_acc: 0.6550\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.6154 - acc: 0.6690 - val_loss: 0.5549 - val_acc: 0.7450\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.5661 - acc: 0.6900 - val_loss: 0.5889 - val_acc: 0.7100\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.5397 - acc: 0.7283 - val_loss: 0.5588 - val_acc: 0.7250\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.5105 - acc: 0.7475 - val_loss: 0.5963 - val_acc: 0.6150\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.4891 - acc: 0.7700 - val_loss: 0.5060 - val_acc: 0.7500\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.4469 - acc: 0.7799 - val_loss: 0.7245 - val_acc: 0.5550\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.4323 - acc: 0.8082 - val_loss: 0.5391 - val_acc: 0.7450\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.3835 - acc: 0.8443 - val_loss: 0.5451 - val_acc: 0.7300\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.3852 - acc: 0.8239 - val_loss: 0.5504 - val_acc: 0.7100\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.3511 - acc: 0.8465 - val_loss: 0.5596 - val_acc: 0.7300\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.3255 - acc: 0.8577 - val_loss: 0.5378 - val_acc: 0.7750\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.3030 - acc: 0.8812 - val_loss: 0.5197 - val_acc: 0.7600\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.2974 - acc: 0.8804 - val_loss: 0.5342 - val_acc: 0.7450\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.2563 - acc: 0.8860 - val_loss: 0.5425 - val_acc: 0.7650\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.2333 - acc: 0.9120 - val_loss: 0.6566 - val_acc: 0.7100\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.2226 - acc: 0.9163 - val_loss: 0.5627 - val_acc: 0.7450\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.2029 - acc: 0.9200 - val_loss: 0.5254 - val_acc: 0.7600\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.1856 - acc: 0.9289 - val_loss: 0.4548 - val_acc: 0.7800\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.1678 - acc: 0.9457 - val_loss: 0.6993 - val_acc: 0.7050\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.1484 - acc: 0.9527 - val_loss: 0.7249 - val_acc: 0.7050\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.1223 - acc: 0.9628 - val_loss: 0.5830 - val_acc: 0.7900\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.1089 - acc: 0.9713 - val_loss: 0.5756 - val_acc: 0.7700\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.1047 - acc: 0.9683 - val_loss: 0.5989 - val_acc: 0.7900\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.0933 - acc: 0.9699 - val_loss: 0.9756 - val_acc: 0.6800\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.0717 - acc: 0.9856 - val_loss: 0.9216 - val_acc: 0.7300\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.0587 - acc: 0.9835 - val_loss: 0.9023 - val_acc: 0.7500\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.0460 - acc: 0.9905 - val_loss: 0.8222 - val_acc: 0.7400\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.0469 - acc: 0.9911 - val_loss: 0.7481 - val_acc: 0.7600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZaZ2HWZsNUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "6248c989-fed6-46da-f463-6dba20b4ea34"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZmXmBcq_8-"
      },
      "source": [
        "## Convolutional Networks with Dropout\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/ee6fa1073247cd2c3d241300caf110d7a7541bc5/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4972644a355067684439596f4f7956415137334d4a772e676966)\n",
        "\n",
        "Ref: https://github.com/mneha4/Training-Neural-Nets---Guidelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu3cqeYQrDeN"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSeLpvY0rH7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e4091c-f0e7-46e9-9d70-f3357f90808b"
      },
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4719 - acc: 0.7835 - val_loss: 0.4760 - val_acc: 0.7500\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4623 - acc: 0.7770 - val_loss: 0.4274 - val_acc: 0.8130\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4639 - acc: 0.7835 - val_loss: 0.4880 - val_acc: 0.7430\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.4653 - acc: 0.7755 - val_loss: 0.4424 - val_acc: 0.7950\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4479 - acc: 0.7880 - val_loss: 0.4572 - val_acc: 0.8000\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4689 - acc: 0.7775 - val_loss: 0.4835 - val_acc: 0.7790\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4411 - acc: 0.7860 - val_loss: 0.5062 - val_acc: 0.7520\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4651 - acc: 0.7825 - val_loss: 0.4404 - val_acc: 0.8060\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4430 - acc: 0.7960 - val_loss: 0.4318 - val_acc: 0.8140\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4408 - acc: 0.7850 - val_loss: 0.4424 - val_acc: 0.7960\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4487 - acc: 0.7900 - val_loss: 0.4627 - val_acc: 0.7950\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4420 - acc: 0.7905 - val_loss: 0.4544 - val_acc: 0.7850\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4366 - acc: 0.8010 - val_loss: 0.4497 - val_acc: 0.7930\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4266 - acc: 0.8090 - val_loss: 0.4617 - val_acc: 0.7800\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.4408 - acc: 0.7985 - val_loss: 0.5094 - val_acc: 0.7670\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4327 - acc: 0.7910 - val_loss: 0.4328 - val_acc: 0.8100\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4315 - acc: 0.7970 - val_loss: 0.4243 - val_acc: 0.8140\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4366 - acc: 0.7970 - val_loss: 0.4558 - val_acc: 0.7840\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4337 - acc: 0.7930 - val_loss: 0.4553 - val_acc: 0.7720\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4176 - acc: 0.7995 - val_loss: 0.4509 - val_acc: 0.8020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdU5yrkUF_b"
      },
      "source": [
        "# Task 2:\n",
        "\n",
        "We have used Dropout to enhance the performance of the CNN model. Can you please use whatever you like to further enhance the performance from `val_acc: 0.7506`? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gq9nskn126K"
      },
      "source": [
        "Simply increasing the number of epochs has improved the performance significantly, as model was not being trained enough on training data before. Model has been trained on 50 epochs three times that makes up 150 epochs in total. Accuracy has increased from 75% to up around 85%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdeemXX-Qm56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d658e45-b94d-40c3-9a66-0aaa62e4e63c"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=50,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.3263 - acc: 0.8605 - val_loss: 0.4208 - val_acc: 0.8270\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.3372 - acc: 0.8485 - val_loss: 0.4220 - val_acc: 0.8330\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.3360 - acc: 0.8525 - val_loss: 0.4004 - val_acc: 0.8340\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.3238 - acc: 0.8595 - val_loss: 0.4731 - val_acc: 0.8120\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3254 - acc: 0.8600 - val_loss: 0.3796 - val_acc: 0.8450\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.3333 - acc: 0.8620 - val_loss: 0.4310 - val_acc: 0.8340\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3450 - acc: 0.8475 - val_loss: 0.4114 - val_acc: 0.8290\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3388 - acc: 0.8520 - val_loss: 0.3997 - val_acc: 0.8260\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.3115 - acc: 0.8700 - val_loss: 0.4394 - val_acc: 0.8270\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3171 - acc: 0.8540 - val_loss: 0.3980 - val_acc: 0.8400\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.3249 - acc: 0.8575 - val_loss: 0.4490 - val_acc: 0.8330\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.3447 - acc: 0.8560 - val_loss: 0.4131 - val_acc: 0.8150\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.3404 - acc: 0.8595 - val_loss: 0.3844 - val_acc: 0.8340\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.3333 - acc: 0.8490 - val_loss: 0.4882 - val_acc: 0.8230\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3285 - acc: 0.8565 - val_loss: 0.4155 - val_acc: 0.8220\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.3176 - acc: 0.8625 - val_loss: 0.4146 - val_acc: 0.8370\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.3331 - acc: 0.8535 - val_loss: 0.3891 - val_acc: 0.8330\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3093 - acc: 0.8670 - val_loss: 0.3985 - val_acc: 0.8390\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3211 - acc: 0.8625 - val_loss: 0.8599 - val_acc: 0.7340\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.3345 - acc: 0.8525 - val_loss: 0.4533 - val_acc: 0.8150\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3115 - acc: 0.8680 - val_loss: 0.3980 - val_acc: 0.8320\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3032 - acc: 0.8685 - val_loss: 0.4190 - val_acc: 0.8480\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.3036 - acc: 0.8620 - val_loss: 0.4277 - val_acc: 0.8330\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.3118 - acc: 0.8605 - val_loss: 0.3875 - val_acc: 0.8410\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.3180 - acc: 0.8665 - val_loss: 0.4138 - val_acc: 0.8300\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.3107 - acc: 0.8610 - val_loss: 0.4015 - val_acc: 0.8500\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.3229 - acc: 0.8535 - val_loss: 0.4240 - val_acc: 0.8330\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.3124 - acc: 0.8620 - val_loss: 0.4546 - val_acc: 0.8230\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.3086 - acc: 0.8700 - val_loss: 0.3986 - val_acc: 0.8530\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.2803 - acc: 0.8800 - val_loss: 0.4170 - val_acc: 0.8370\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3084 - acc: 0.8650 - val_loss: 0.3965 - val_acc: 0.8300\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.2948 - acc: 0.8665 - val_loss: 0.6197 - val_acc: 0.7810\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3129 - acc: 0.8725 - val_loss: 0.3613 - val_acc: 0.8430\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3025 - acc: 0.8745 - val_loss: 0.3948 - val_acc: 0.8470\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3197 - acc: 0.8580 - val_loss: 0.6014 - val_acc: 0.7750\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3042 - acc: 0.8670 - val_loss: 0.4352 - val_acc: 0.8290\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.2920 - acc: 0.8690 - val_loss: 0.3993 - val_acc: 0.8350\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.2896 - acc: 0.8815 - val_loss: 0.3729 - val_acc: 0.8410\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.3066 - acc: 0.8645 - val_loss: 0.3785 - val_acc: 0.8510\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.2970 - acc: 0.8740 - val_loss: 0.4365 - val_acc: 0.8320\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.3035 - acc: 0.8760 - val_loss: 0.4029 - val_acc: 0.8380\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.2986 - acc: 0.8710 - val_loss: 0.3733 - val_acc: 0.8380\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.3001 - acc: 0.8705 - val_loss: 0.4354 - val_acc: 0.8350\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.3086 - acc: 0.8675 - val_loss: 0.3766 - val_acc: 0.8450\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.2765 - acc: 0.8830 - val_loss: 0.4359 - val_acc: 0.8400\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.2987 - acc: 0.8740 - val_loss: 0.3539 - val_acc: 0.8460\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.2697 - acc: 0.8865 - val_loss: 0.4902 - val_acc: 0.8220\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.3007 - acc: 0.8655 - val_loss: 0.3583 - val_acc: 0.8540\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.2985 - acc: 0.8795 - val_loss: 0.5328 - val_acc: 0.8080\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.2943 - acc: 0.8770 - val_loss: 0.4268 - val_acc: 0.8550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOgUkvC3IPmR"
      },
      "source": [
        "Tranfer learning with pre trained VGG16 model fine tuned on our training data has improved the test accuracy to 92%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8LQr0gcE7Vb",
        "outputId": "0e317032-4fc8-4806-f620-f2d0b8e3b13e"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "IMG_SIZE= 224\n",
        "img_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "model = VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=img_input,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv0tk0pBF8pK",
        "outputId": "fb9f42e4-cb00-4087-f45d-1a47209f1b21"
      },
      "source": [
        "last_layer = model.get_layer('block5_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "x = Dense(128, activation='relu', name='fc1')(x)\n",
        "x = Dense(64, activation='relu', name='fc2')(x)\n",
        "out = Dense(1, activation='sigmoid', name='output')(x)  ## 2 classes\n",
        "model = Model(img_input, out)\n",
        "\n",
        "for layer in model.layers[:-3]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 17,934,401\n",
            "Trainable params: 3,219,713\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEo_edB7HeOt"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_GJkyCuHOQE",
        "outputId": "c10cf88b-c6e4-4045-a7d9-3051755b38c5"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 38s 332ms/step - loss: 0.5290 - acc: 0.7385 - val_loss: 0.2672 - val_acc: 0.8840\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.3673 - acc: 0.8315 - val_loss: 0.3082 - val_acc: 0.8730\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.3362 - acc: 0.8515 - val_loss: 0.2324 - val_acc: 0.8990\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2909 - acc: 0.8720 - val_loss: 0.2002 - val_acc: 0.9130\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.3112 - acc: 0.8660 - val_loss: 0.1962 - val_acc: 0.9250\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2977 - acc: 0.8730 - val_loss: 0.2064 - val_acc: 0.9170\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2672 - acc: 0.8860 - val_loss: 0.2172 - val_acc: 0.9110\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 33s 333ms/step - loss: 0.3039 - acc: 0.8645 - val_loss: 0.2004 - val_acc: 0.9200\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2693 - acc: 0.8870 - val_loss: 0.2007 - val_acc: 0.9190\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2563 - acc: 0.8880 - val_loss: 0.2153 - val_acc: 0.9080\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2569 - acc: 0.8895 - val_loss: 0.2291 - val_acc: 0.9090\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2373 - acc: 0.9000 - val_loss: 0.2204 - val_acc: 0.8970\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2458 - acc: 0.8880 - val_loss: 0.1889 - val_acc: 0.9230\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2449 - acc: 0.8980 - val_loss: 0.1823 - val_acc: 0.9210\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2598 - acc: 0.8890 - val_loss: 0.2646 - val_acc: 0.8950\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2692 - acc: 0.8830 - val_loss: 0.2373 - val_acc: 0.8970\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2296 - acc: 0.9020 - val_loss: 0.1830 - val_acc: 0.9200\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2452 - acc: 0.8895 - val_loss: 0.1872 - val_acc: 0.9220\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2360 - acc: 0.8915 - val_loss: 0.2025 - val_acc: 0.9240\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.2408 - acc: 0.9025 - val_loss: 0.2017 - val_acc: 0.9170\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.2115 - acc: 0.9080 - val_loss: 0.1984 - val_acc: 0.9170\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.2200 - acc: 0.9130 - val_loss: 0.2348 - val_acc: 0.8910\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2137 - acc: 0.9085 - val_loss: 0.1942 - val_acc: 0.9270\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.2366 - acc: 0.9010 - val_loss: 0.2047 - val_acc: 0.9240\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.2093 - acc: 0.9070 - val_loss: 0.1936 - val_acc: 0.9170\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.2092 - acc: 0.9135 - val_loss: 0.2129 - val_acc: 0.9110\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.2160 - acc: 0.9135 - val_loss: 0.2370 - val_acc: 0.9090\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2289 - acc: 0.8910 - val_loss: 0.2031 - val_acc: 0.9160\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.2142 - acc: 0.9055 - val_loss: 0.2054 - val_acc: 0.9130\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.2003 - acc: 0.9155 - val_loss: 0.1978 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}